{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82f8b08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "from file_extraction import *\n",
    "from to_dataframe import *\n",
    "from clean_dfs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d26b4e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_dict, academy_csvs_file_names = extract()\n",
    "dataframes = convert(files_dict, academy_csvs_file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2763b762",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_academy_csv = dataframes['academy_csv']\n",
    "df_academy_csv = clean_academy_csv(df_academy_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "803f124f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv = dataframes['csv']\n",
    "df_csv = clean_talent_csv(df_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b302b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json = dataframes['json']\n",
    "df_json = clean_talent_json(df_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ac39af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_txt = dataframes['txt']\n",
    "df_txt = clean_talent_txt(df_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8db65c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# makes an address table dataframe \n",
    "def generate_address_df(df):\n",
    "    addresses = list()\n",
    "    # for each row in the talent csv files, add each unique address, city and postcode to a list\n",
    "    for index, row in df.iterrows():\n",
    "                address_list = list()\n",
    "                address_list.append(row[\"address\"])\n",
    "                address_list.append(row[\"city\"])\n",
    "                address_list.append(row[\"postcode\"])\n",
    "                if address_list not in addresses:\n",
    "                    addresses.append(address_list)\n",
    "                    \n",
    "    address_table = pd.DataFrame(addresses, columns=[\"address\", \"city\", \"postcode\"])\n",
    "    address_table.index = address_table.index + 1\n",
    "    address_table['address_id'] = address_table.index\n",
    "    return address_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df7d0dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "address_table = generate_address_df(df_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "69f62df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_person_ids(applicants):\n",
    "    applicants = applicants.reset_index().reset_index().drop(['index', 'id'], axis=1).rename(columns={'level_0':'person_id'})\n",
    "    return applicants\n",
    "\n",
    " \n",
    "\n",
    "def generate_candidates_df(applicants, talents, sparta_day_results):\n",
    "    applicants_and_talents = applicants.merge(talents, \n",
    "                                              left_on=['name', 'invite_date'], \n",
    "                                              right_on=['name', 'date'], \n",
    "                                              how='left')\n",
    "\n",
    "    candidates = applicants_and_talents.merge(sparta_day_results, \n",
    "                                              left_on=['name', 'invite_date'], \n",
    "                                              right_on=['name', 'date'], \n",
    "                                              how='left')\n",
    "\n",
    "    candidates = candidates.drop(candidates.index[candidates.person_id.duplicated().tolist()].tolist())\n",
    "    candidates.reset_index(drop=True, inplace=True)\n",
    "    candidates['person_id'] = candidates.index + 1\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7090338b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def address_id_in_candidates(candidates, address_table):\n",
    "    merged = pd.merge(candidates, address_table, on='address')\n",
    "    merged = merged.drop(columns=['city_x', 'address', 'postcode_x', 'city_y', 'postcode_y', 'date_y'])\n",
    "    merged = merged.rename(columns={\"date_x\": \"date\"})\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fa4d0f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = generate_candidates_df(get_person_ids(df_csv), df_json, df_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bf1bbe34",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = address_id_in_candidates(candidates, address_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "234129f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_courses_table(dataframe):\n",
    "    courses_df  = dataframe\n",
    "    courses_df = pd.DataFrame().assign(course = courses_df['course'], date = courses_df['date'])\n",
    "    courses_df['course_id'] = courses_df.groupby(['course']).ngroup()\n",
    "    courses_df = courses_df[['course', 'course_id', 'date']].copy()\n",
    "    courses_df.set_index('course_id', inplace=True)\n",
    "    courses_df.groupby(['course','date'])\n",
    "    courses_df = courses_df.drop_duplicates()\n",
    "    courses_df = courses_df.reset_index()\n",
    "    courses_df.index = courses_df.index + 1\n",
    "    courses_df['course_id'] = courses_df.index\n",
    "    courses_df = courses_df.rename(columns={\"course\": \"course_name\"})\n",
    "    \n",
    "    return courses_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1c493ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "courses_table = generate_courses_table(df_academy_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e255bc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# makes a weakness table dataframe\n",
    "def generate_weakness_df(df):\n",
    "    weaknesses_list = list()\n",
    "    \n",
    "    # for each row in the dataframe add distinct weaknesses to a list\n",
    "    for index, row in df.iterrows():\n",
    "        for weakness in row[\"weaknesses\"]:\n",
    "            if weakness not in weaknesses_list:\n",
    "                weaknesses_list.append(weakness)\n",
    "                \n",
    "    # turn weakneseses list into a dataframe and add a column for the weakness id            \n",
    "    weakness_table = pd.DataFrame(weaknesses_list, columns=['weakness'])\n",
    "    weakness_table.index = weakness_table.index + 1\n",
    "    weakness_table['weakness_id'] = weakness_table.index\n",
    "    return weakness_table          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fae7dfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "weakness_df = generate_weakness_df(df_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c63f7c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes talent jsons, talent csv, weakness dataframe as arguments\n",
    "def generate_weakness_junc_df(candidates, weakness_df):\n",
    "    weakness_junc_list = list()\n",
    "    \n",
    "    # for each row in the merged dataframe add (id, weakness) to a new dataframe for each weakness in weaknesses list\n",
    "    for index, row in candidates.iterrows():\n",
    "        person_id = row['person_id']\n",
    "        weaknesses = row['weaknesses']\n",
    "        \n",
    "        if type(weaknesses) == list:\n",
    "            for weakness in weaknesses:\n",
    "                weakness_junc_list.append([person_id, weakness])\n",
    "    \n",
    "    weakness_junc = pd.DataFrame(weakness_junc_list, columns=['person_id', 'weakness'])\n",
    "    \n",
    "    weakness_junc = pd.merge(weakness_junc, weakness_df, on='weakness')[['person_id', 'weakness_id']] \n",
    "        \n",
    "    return weakness_junc      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a7a1c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "weakness_junc_df = generate_weakness_junc_df(candidates, weakness_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44bd0b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_strengths_df(df):\n",
    "    # Create a new DataFrame for strengths column only\n",
    "    column_names = ['name', 'strengths']\n",
    "    strengths = df[column_names]\n",
    "\n",
    "    # Initialize an empty list to store row data\n",
    "    strengths_list = []\n",
    "\n",
    "    # Iterate over all rows\n",
    "    for index, row in strengths.iterrows():\n",
    "        strengths_list_row = row['strengths']\n",
    "\n",
    "        # Iterate over each strength in the list\n",
    "        for strength in strengths_list_row:\n",
    "            if strength not in strengths_list:\n",
    "                # Append row data to the list\n",
    "                strengths_list.append(strength)\n",
    "\n",
    "    # Create a new DataFrame from the list\n",
    "    strengths_df = pd.DataFrame({'strength': strengths_list})\n",
    "    strengths_df.index = strengths_df.index + 1\n",
    "    strengths_df['strength_id'] = strengths_df.index\n",
    "    # Return the new DataFrame\n",
    "    return strengths_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e1f708a",
   "metadata": {},
   "outputs": [],
   "source": [
    "strengths_df = generate_strengths_df(df_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a405d358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes talent jsons, talent csv, weakness dataframe as arguments\n",
    "def generate_strengths_junc_df(candidates, strengths_df):\n",
    "    strengths_junc_list = list()\n",
    "    \n",
    "    for index, row in candidates.iterrows():\n",
    "        person_id = row['person_id']\n",
    "        strengths = row['strengths']\n",
    "        \n",
    "        if type(strengths) == list:\n",
    "            for strength in strengths:\n",
    "                strengths_junc_list.append([person_id, strength])\n",
    "    \n",
    "    strengths_junc = pd.DataFrame(strengths_junc_list, columns=['person_id', 'strength'])\n",
    "\n",
    "    strengths_junc = pd.merge(strengths_junc, strengths_df, on='strength')[['person_id', 'strength_id']] \n",
    "        \n",
    "    return strengths_junc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "94e5aad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "strengths_junc_df = generate_strengths_junc_df(candidates, strengths_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf9bc72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tss_df(df, candidates):\n",
    "    #Create names lists\n",
    "    names = []\n",
    "    technologies = []\n",
    "    self_scores = []\n",
    "\n",
    "    #Loop through dataframe\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            techs = list(row['tech_self_score'].keys())\n",
    "            for tech in techs:\n",
    "                names.append(row['name'].upper())\n",
    "                technologies.append(tech)\n",
    "                self_scores.append(row['tech_self_score'][tech])\n",
    "        except AttributeError:\n",
    "            continue\n",
    "\n",
    "    tech_self_scores = pd.DataFrame({'name':names, 'technology':technologies, 'self_score': self_scores})\n",
    "    merged = pd.merge(tech_self_scores, candidates, on='name')[['person_id', 'technology', 'self_score']] \n",
    "    \n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41aebc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_scores = generate_tss_df(df_json, candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "939d0d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_academy_table(df_academy_csv, courses_table, candidates):\n",
    "    merged = pd.merge(df_academy_csv, courses_table, left_on='course', right_on='course_name')[['name', 'course_id']]\n",
    "    academy_table = pd.merge(merged, candidates, on='name')[['person_id', 'course_id']] \n",
    "    return academy_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "01695550",
   "metadata": {},
   "outputs": [],
   "source": [
    "academy_table = generate_academy_table(df_academy_csv, courses_table, candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8df2b867",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_trainers_table(df):\n",
    "    old_name = \"Ely Kely\"\n",
    "    new_name = \"Elly Kelly\"\n",
    "    df.loc[:, [\"trainer\"]] = df.loc[:, [\"trainer\"]].replace(old_name, new_name)\n",
    "    trainers_course = df[[\"trainer\", \"course\", \"date\"]]\n",
    "    trainer_course = trainers_course.drop_duplicates(subset = [\"date\"], keep= \"first\")\n",
    "    trainer_course['trainer_id'] = range(1, len(trainer_course) + 1)\n",
    "    trainers = trainer_course.set_index('trainer_id')\n",
    "    trainers_table = trainers.drop(['course', 'date'], axis=1).drop_duplicates()\n",
    "    trainers = trainers.rename(columns={\"course\": \"course_name\"})\n",
    "    trainers['trainer_id'] = trainers.index\n",
    "    return trainers, trainers_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9fe40019",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mankabir\\AppData\\Local\\Temp\\ipykernel_15640\\2851188400.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  trainer_course['trainer_id'] = range(1, len(trainer_course) + 1)\n"
     ]
    }
   ],
   "source": [
    "trainers, trainers_table = generate_trainers_table(df_academy_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "00b2cea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_trainers_junc(df_trainers, df_courses):\n",
    "    trainers_junc = pd.merge(df_trainers, df_courses, on='course_name')[['course_id', 'trainer_id']] \n",
    "    return trainers_junc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea52def2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainers_junc = generate_trainers_junc(trainers, courses_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8e6b752b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def use(key: str):\n",
    "    s3 = boto3.client('s3')\n",
    "    obj = s3.get_object(Bucket='data-eng-228-final-project', Key=key)\n",
    "    filetype = key[key.index('.'):]\n",
    "    if filetype == '.csv':\n",
    "        data = pd.read_csv(obj['Body'])\n",
    "    elif filetype == '.json':\n",
    "        data = json.load(obj['Body'])\n",
    "    elif filetype == '.txt':\n",
    "        data = obj['Body'].read().decode('utf-8')\n",
    "    return data\n",
    "\n",
    "\n",
    "def make_wide(table):\n",
    "    academy_results_wide = table.pivot(index=['name', 'week_no'],\n",
    "                                       columns='attribute',\n",
    "                                       values='score')\n",
    "    academy_results = academy_results_wide.reset_index()\n",
    "    return academy_results\n",
    "\n",
    "\n",
    "def make_upper(df, attribute: str='name'):\n",
    "    return df[attribute].transform(lambda attr: attr.upper())\n",
    "\n",
    "\n",
    "def transform_acares(keystrings: list):\n",
    "    tables = []\n",
    "\n",
    "    for keystring in keystrings:\n",
    "        current_ar = use(keystring)\n",
    "        current_ar['name'] = make_upper(current_ar, 'name')\n",
    "        raw_attributes = current_ar.columns[2:]\n",
    "\n",
    "        names = []\n",
    "        week_numbers = []\n",
    "        attributes = []\n",
    "        scores = []\n",
    "\n",
    "        for name in current_ar['name']:\n",
    "            for attribute in raw_attributes:\n",
    "                names.append(name)\n",
    "                week_numbers.append(attribute[attribute.index('W') + 1:])\n",
    "                attributes.append(attribute[:attribute.index('_')])\n",
    "                scores.append(float(current_ar[current_ar['name'] == name][attribute].tolist()[0]))\n",
    "        academy_results_long = pd.DataFrame({'name': names,\n",
    "                                             'week_no': week_numbers,\n",
    "                                             'attribute': attributes,\n",
    "                                             'score': scores})\n",
    "        tables.append(academy_results_long)\n",
    "    return pd.concat(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2dce2e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client('s3')\n",
    "files_dict = {'academy_csv': [], 'json': [], 'txt': [], 'csv': []}\n",
    "academy_csvs_file_names = extract_file_type(s3_client, 'Academy', files_dict, 'csv')\n",
    "df1 = transform_acares(academy_csvs_file_names)\n",
    "academy_results = make_wide(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "95ab76fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_person_id_to_acares(candidates, academy_results):\n",
    "    passed_candidates = candidates[(candidates.result == 'PASS').tolist()]\n",
    "    passed_candidates\n",
    "\n",
    " \n",
    "\n",
    "    academy_results = academy_results.merge(passed_candidates[['person_id', 'name']], left_on='name', right_on='name')\n",
    "    return academy_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "64548b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "academy_results = join_person_id_to_acares(candidates, academy_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bf2659c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>week_no</th>\n",
       "      <th>Analytic</th>\n",
       "      <th>Determined</th>\n",
       "      <th>Imaginative</th>\n",
       "      <th>Independent</th>\n",
       "      <th>Professional</th>\n",
       "      <th>Studious</th>\n",
       "      <th>person_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADAH SPENCERS</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADAH SPENCERS</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADAH SPENCERS</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADAH SPENCERS</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADAH SPENCERS</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>ZOLLIE DANKS</td>\n",
       "      <td>4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>ZOLLIE DANKS</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3263</th>\n",
       "      <td>ZOLLIE DANKS</td>\n",
       "      <td>6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3264</th>\n",
       "      <td>ZOLLIE DANKS</td>\n",
       "      <td>7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3265</th>\n",
       "      <td>ZOLLIE DANKS</td>\n",
       "      <td>8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3266 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               name week_no  Analytic  Determined  Imaginative  Independent  \\\n",
       "0     ADAH SPENCERS       1       5.0         2.0          3.0          3.0   \n",
       "1     ADAH SPENCERS       2       4.0         1.0          1.0          5.0   \n",
       "2     ADAH SPENCERS       3       6.0         1.0          2.0          3.0   \n",
       "3     ADAH SPENCERS       4       4.0         8.0          5.0          6.0   \n",
       "4     ADAH SPENCERS       5       2.0         8.0          5.0          5.0   \n",
       "...             ...     ...       ...         ...          ...          ...   \n",
       "3261   ZOLLIE DANKS       4       8.0         3.0          5.0          4.0   \n",
       "3262   ZOLLIE DANKS       5       5.0         5.0          8.0          4.0   \n",
       "3263   ZOLLIE DANKS       6       7.0         7.0          7.0          8.0   \n",
       "3264   ZOLLIE DANKS       7       4.0         8.0          6.0          8.0   \n",
       "3265   ZOLLIE DANKS       8       4.0         8.0          8.0          8.0   \n",
       "\n",
       "      Professional  Studious  person_id  \n",
       "0              5.0       4.0        288  \n",
       "1              1.0       4.0        288  \n",
       "2              7.0       2.0        288  \n",
       "3              7.0       3.0        288  \n",
       "4              3.0       3.0        288  \n",
       "...            ...       ...        ...  \n",
       "3261           6.0       6.0       4579  \n",
       "3262           7.0       7.0       4579  \n",
       "3263           7.0       4.0       4579  \n",
       "3264           8.0       8.0       4579  \n",
       "3265           6.0       7.0       4579  \n",
       "\n",
       "[3266 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(academy_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "243c8584",
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes in a df and import its to table in a databse .db file\n",
    "def df_to_db(df: pd.DataFrame, table_name: str, database_name: str):\n",
    "    con = sqlite3.connect(database_name)\n",
    "    df.to_sql(table_name, con, if_exists='append', index=False)\n",
    "    con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d811c322",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_df_to_db(df_list: [], table_names:[], database_name:str):\n",
    "    for df, table_name in zip(df_list, table_names):\n",
    "        df_to_db(df, table_name, database_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "25174bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [address_table, candidates, courses_table, weakness_df, weakness_junc_df, strengths_df, strengths_junc_df, tech_scores, academy_table, trainers_table, trainers_junc, academy_results]\n",
    "table_list =['address', 'candidates', 'courses', 'weakness', 'weakness_junc', 'strength', 'strength_junc', 'tech_scores', 'academy', 'trainers', 'trainers_junc', 'academy_results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4ca6a718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SQLite connection\n",
    "conn = sqlite3.connect('my_database.db')\n",
    "c = conn.cursor()\n",
    "\n",
    "# Enable foreign key constraint\n",
    "c.execute(\"PRAGMA foreign_keys = ON;\")\n",
    "\n",
    "# Define the schema as a list of strings\n",
    "schemas = [\n",
    "    '''\n",
    "    CREATE TABLE address (\n",
    "        address_id INTEGER PRIMARY KEY,\n",
    "        address TEXT,\n",
    "        city TEXT,\n",
    "        postcode TEXT\n",
    "    )\n",
    "    ''',\n",
    "    '''\n",
    "    CREATE TABLE candidates (\n",
    "        person_id INTEGER PRIMARY KEY,\n",
    "        name TEXT,\n",
    "        invite_date TEXT,\n",
    "        invited_by TEXT,\n",
    "        address_id INTEGER,\n",
    "        gender TEXT,\n",
    "        dob TEXT,\n",
    "        email TEXT,\n",
    "        phone_number TEXT,\n",
    "        uni TEXT,\n",
    "        degree INTEGER,\n",
    "        self_development INTEGER,\n",
    "        result TEXT,\n",
    "        geo_flex INTEGER,\n",
    "        financial_support_self INTEGER,\n",
    "        course_interest TEXT,\n",
    "        sparta_day_date TEXT,\n",
    "        psychometrics_score INTEGER,\n",
    "        presentation_score INTEGER,\n",
    "        sparta_day_location TEXT,\n",
    "        date TEXT,\n",
    "        academy TEXT,\n",
    "        FOREIGN KEY(address_id) REFERENCES address(address_id)\n",
    "    )\n",
    "    ''',\n",
    "    '''\n",
    "    CREATE TABLE tech_scores (\n",
    "        person_id INTEGER,\n",
    "        tech_scores_id INTEGER,\n",
    "        scores INTEGER,\n",
    "        PRIMARY KEY (person_id, tech_scores_id),\n",
    "        FOREIGN KEY(person_id) REFERENCES candidates(person_id)\n",
    "    )\n",
    "    ''',\n",
    "    '''\n",
    "    CREATE TABLE weakness (\n",
    "        weakness_id INTEGER PRIMARY KEY,\n",
    "        weakness TEXT\n",
    "    )\n",
    "    ''',\n",
    "    '''\n",
    "    CREATE TABLE weakness_junc (\n",
    "        person_id INTEGER,\n",
    "        weakness_id INTEGER,\n",
    "        PRIMARY KEY (person_id, weakness_id),\n",
    "        FOREIGN KEY(person_id) REFERENCES candidates(person_id),\n",
    "        FOREIGN KEY(weakness_id) REFERENCES weakness(weakness_id)\n",
    "    )\n",
    "    ''',\n",
    "    '''\n",
    "    CREATE TABLE strength (\n",
    "        strength_id INTEGER PRIMARY KEY,\n",
    "        strength TEXT\n",
    "    )\n",
    "    ''',\n",
    "    '''\n",
    "    CREATE TABLE strength_junc (\n",
    "        person_id INTEGER,\n",
    "        strength_id INTEGER,\n",
    "        PRIMARY KEY (person_id, strength_id),\n",
    "        FOREIGN KEY(person_id) REFERENCES candidates(person_id),\n",
    "        FOREIGN KEY(strength_id) REFERENCES strength(strength_id)\n",
    "    )\n",
    "    ''',\n",
    "    '''\n",
    "    CREATE TABLE academy_results (\n",
    "        person_id INTEGER,\n",
    "        week_no INTEGER,\n",
    "        analytic INTEGER,\n",
    "        independant INTEGER,\n",
    "        determined INTEGER,\n",
    "        professional INTEGER,\n",
    "        imaginative INTEGER,\n",
    "        PRIMARY KEY (person_id, week_no),\n",
    "        FOREIGN KEY(person_id) REFERENCES candidates(person_id)\n",
    "    )\n",
    "    ''',\n",
    "    '''\n",
    "    CREATE TABLE courses (\n",
    "        course_id INTEGER PRIMARY KEY,\n",
    "        course_name TEXT,\n",
    "        date TEXT\n",
    "    )\n",
    "    ''',\n",
    "    '''\n",
    "    CREATE TABLE trainers (\n",
    "        trainer_id INTEGER PRIMARY KEY,\n",
    "        trainer_name TEXT\n",
    "    )\n",
    "    ''',\n",
    "    '''\n",
    "    CREATE TABLE trainers_junc (\n",
    "        course_id INTEGER,\n",
    "        trainer_id INTEGER,\n",
    "        PRIMARY KEY (course_id, trainer_id),\n",
    "        FOREIGN KEY(course_id) REFERENCES courses(course_id),\n",
    "        FOREIGN KEY(trainer_id) REFERENCES Trainers(trainer_id)\n",
    "    )\n",
    "    ''',\n",
    "    '''\n",
    "    CREATE TABLE academy (\n",
    "        person_id INTEGER,\n",
    "        course_id INTEGER,\n",
    "        PRIMARY KEY (person_id, course_id),\n",
    "        FOREIGN KEY(person_id) REFERENCES candidates(person_id),\n",
    "        FOREIGN KEY(course_id) REFERENCES courses(course_id)\n",
    "    )\n",
    "    '''\n",
    "]\n",
    "\n",
    "# Execute each schema\n",
    "for schema in schemas:\n",
    "    c.execute(schema)\n",
    "\n",
    "# Commit the changes and close the connection\n",
    "conn.commit()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f2bd4047",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df_to_db(df_list, table_list, 'my_database24.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1ba924c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_id</th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "      <th>dob</th>\n",
       "      <th>email</th>\n",
       "      <th>phone_number</th>\n",
       "      <th>uni</th>\n",
       "      <th>degree</th>\n",
       "      <th>invited_by</th>\n",
       "      <th>invite_date</th>\n",
       "      <th>date</th>\n",
       "      <th>self_development</th>\n",
       "      <th>geo_flex</th>\n",
       "      <th>financial_support_self</th>\n",
       "      <th>result</th>\n",
       "      <th>course_interest</th>\n",
       "      <th>psychometrics_score</th>\n",
       "      <th>presentation_score</th>\n",
       "      <th>academy</th>\n",
       "      <th>address_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ESME TRUSSLOVE</td>\n",
       "      <td>F</td>\n",
       "      <td>1994-08-04</td>\n",
       "      <td>etrusslove0@google.es</td>\n",
       "      <td>442957830228</td>\n",
       "      <td>Saint George's Hospital Medical School, Univer...</td>\n",
       "      <td>2.1</td>\n",
       "      <td>BRUNO BELLBROOK</td>\n",
       "      <td>2019-04-10</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>London Academy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>MATTHAEUS AUDAS</td>\n",
       "      <td>M</td>\n",
       "      <td>NaT</td>\n",
       "      <td>maudas1@mapquest.com</td>\n",
       "      <td>449577280155</td>\n",
       "      <td>Keele University</td>\n",
       "      <td>2.1</td>\n",
       "      <td>DORIS BELLASIS</td>\n",
       "      <td>2019-04-30</td>\n",
       "      <td>2019-04-30</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>PASS</td>\n",
       "      <td>DATA</td>\n",
       "      <td>59.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>London Academy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>CHEREY TOLLFREE</td>\n",
       "      <td>F</td>\n",
       "      <td>1992-12-08</td>\n",
       "      <td>ctollfree2@netvibes.com</td>\n",
       "      <td>445887496002</td>\n",
       "      <td>King's College London, University of London</td>\n",
       "      <td>2.1</td>\n",
       "      <td>GISMO TILLING</td>\n",
       "      <td>2019-04-25</td>\n",
       "      <td>2019-04-25</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>PASS</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>59.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Birmingham Academy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>ERYN SPEERS</td>\n",
       "      <td>F</td>\n",
       "      <td>NaT</td>\n",
       "      <td>espeers3@shinystat.com</td>\n",
       "      <td>441487870613</td>\n",
       "      <td>University of Edinburgh</td>\n",
       "      <td>2.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>THEADORA BERKELAY</td>\n",
       "      <td>F</td>\n",
       "      <td>1995-11-03</td>\n",
       "      <td>tberkelay4@godaddy.com</td>\n",
       "      <td>448414683619</td>\n",
       "      <td>University of Leicester</td>\n",
       "      <td>2.1</td>\n",
       "      <td>STACEY BROAD</td>\n",
       "      <td>2019-04-02</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>London Academy</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4698</th>\n",
       "      <td>4687</td>\n",
       "      <td>CLYVE GILLHESPY</td>\n",
       "      <td>M</td>\n",
       "      <td>1995-12-15</td>\n",
       "      <td>cgillhespybj@buzzfeed.com</td>\n",
       "      <td>449043432218</td>\n",
       "      <td>University of Liverpool</td>\n",
       "      <td>2.1</td>\n",
       "      <td>BRUNO BELLBROOK</td>\n",
       "      <td>2019-09-26</td>\n",
       "      <td>2019-09-26</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>PASS</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>59.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Birmingham Academy</td>\n",
       "      <td>4594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4699</th>\n",
       "      <td>4688</td>\n",
       "      <td>VACLAV PIETESCH</td>\n",
       "      <td>M</td>\n",
       "      <td>1994-11-09</td>\n",
       "      <td>vpieteschbk@mac.com</td>\n",
       "      <td>444556316125</td>\n",
       "      <td>Sheffield Hallam University</td>\n",
       "      <td>2.2</td>\n",
       "      <td>STACEY BROAD</td>\n",
       "      <td>2019-09-12</td>\n",
       "      <td>2019-09-12</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>FAIL</td>\n",
       "      <td>ENGINEERING</td>\n",
       "      <td>61.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Birmingham Academy</td>\n",
       "      <td>4595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4700</th>\n",
       "      <td>4689</td>\n",
       "      <td>KASSI LUCIO</td>\n",
       "      <td>F</td>\n",
       "      <td>1994-04-24</td>\n",
       "      <td>kluciobl@exblog.jp</td>\n",
       "      <td>448343429323</td>\n",
       "      <td>University of Buckingham</td>\n",
       "      <td>2.1</td>\n",
       "      <td>FIFI ETON</td>\n",
       "      <td>2019-09-03</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>London Academy</td>\n",
       "      <td>4596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4701</th>\n",
       "      <td>4690</td>\n",
       "      <td>VIVIANNA LETTY</td>\n",
       "      <td>F</td>\n",
       "      <td>NaT</td>\n",
       "      <td>vlettybm@google.com.hk</td>\n",
       "      <td>445347583140</td>\n",
       "      <td>Leeds Metropolitan University</td>\n",
       "      <td>1.0</td>\n",
       "      <td>BRUNO BELLBROOK</td>\n",
       "      <td>2019-09-19</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Birmingham Academy</td>\n",
       "      <td>4597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4702</th>\n",
       "      <td>4691</td>\n",
       "      <td>MERCIE GROGER</td>\n",
       "      <td>F</td>\n",
       "      <td>1997-05-10</td>\n",
       "      <td>mgrogerbn@timesonline.co.uk</td>\n",
       "      <td>446622394688</td>\n",
       "      <td>ifs University College</td>\n",
       "      <td>3.0</td>\n",
       "      <td>RUPERT RIPPLE</td>\n",
       "      <td>2019-09-12</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Birmingham Academy</td>\n",
       "      <td>4598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4691 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      person_id               name gender        dob  \\\n",
       "0             1     ESME TRUSSLOVE      F 1994-08-04   \n",
       "1             2    MATTHAEUS AUDAS      M        NaT   \n",
       "2             3    CHEREY TOLLFREE      F 1992-12-08   \n",
       "3             4        ERYN SPEERS      F        NaT   \n",
       "4             5  THEADORA BERKELAY      F 1995-11-03   \n",
       "...         ...                ...    ...        ...   \n",
       "4698       4687    CLYVE GILLHESPY      M 1995-12-15   \n",
       "4699       4688    VACLAV PIETESCH      M 1994-11-09   \n",
       "4700       4689        KASSI LUCIO      F 1994-04-24   \n",
       "4701       4690     VIVIANNA LETTY      F        NaT   \n",
       "4702       4691      MERCIE GROGER      F 1997-05-10   \n",
       "\n",
       "                            email  phone_number  \\\n",
       "0           etrusslove0@google.es  442957830228   \n",
       "1            maudas1@mapquest.com  449577280155   \n",
       "2         ctollfree2@netvibes.com  445887496002   \n",
       "3          espeers3@shinystat.com  441487870613   \n",
       "4          tberkelay4@godaddy.com  448414683619   \n",
       "...                           ...           ...   \n",
       "4698    cgillhespybj@buzzfeed.com  449043432218   \n",
       "4699          vpieteschbk@mac.com  444556316125   \n",
       "4700           kluciobl@exblog.jp  448343429323   \n",
       "4701       vlettybm@google.com.hk  445347583140   \n",
       "4702  mgrogerbn@timesonline.co.uk  446622394688   \n",
       "\n",
       "                                                    uni  degree  \\\n",
       "0     Saint George's Hospital Medical School, Univer...     2.1   \n",
       "1                                      Keele University     2.1   \n",
       "2           King's College London, University of London     2.1   \n",
       "3                               University of Edinburgh     2.1   \n",
       "4                               University of Leicester     2.1   \n",
       "...                                                 ...     ...   \n",
       "4698                            University of Liverpool     2.1   \n",
       "4699                        Sheffield Hallam University     2.2   \n",
       "4700                           University of Buckingham     2.1   \n",
       "4701                      Leeds Metropolitan University     1.0   \n",
       "4702                             ifs University College     3.0   \n",
       "\n",
       "           invited_by invite_date       date self_development geo_flex  \\\n",
       "0     BRUNO BELLBROOK  2019-04-10        NaT              NaN      NaN   \n",
       "1      DORIS BELLASIS  2019-04-30 2019-04-30              YES      YES   \n",
       "2       GISMO TILLING  2019-04-25 2019-04-25              YES      YES   \n",
       "3                 NaN         NaT        NaT              NaN      NaN   \n",
       "4        STACEY BROAD  2019-04-02        NaT              NaN      NaN   \n",
       "...               ...         ...        ...              ...      ...   \n",
       "4698  BRUNO BELLBROOK  2019-09-26 2019-09-26              YES      YES   \n",
       "4699     STACEY BROAD  2019-09-12 2019-09-12              YES      YES   \n",
       "4700        FIFI ETON  2019-09-03        NaT              NaN      NaN   \n",
       "4701  BRUNO BELLBROOK  2019-09-19        NaT              NaN      NaN   \n",
       "4702    RUPERT RIPPLE  2019-09-12        NaT              NaN      NaN   \n",
       "\n",
       "     financial_support_self result course_interest  psychometrics_score  \\\n",
       "0                       NaN    NaN             NaN                 39.0   \n",
       "1                       YES   PASS            DATA                 59.0   \n",
       "2                       YES   PASS        BUSINESS                 59.0   \n",
       "3                       NaN    NaN             NaN                  NaN   \n",
       "4                       NaN    NaN             NaN                 59.0   \n",
       "...                     ...    ...             ...                  ...   \n",
       "4698                    YES   PASS        BUSINESS                 59.0   \n",
       "4699                     NO   FAIL     ENGINEERING                 61.0   \n",
       "4700                    NaN    NaN             NaN                 60.0   \n",
       "4701                    NaN    NaN             NaN                 56.0   \n",
       "4702                    NaN    NaN             NaN                 43.0   \n",
       "\n",
       "      presentation_score             academy  address_id  \n",
       "0                   23.0      London Academy           1  \n",
       "1                   20.0      London Academy           2  \n",
       "2                   18.0  Birmingham Academy           3  \n",
       "3                    NaN                 NaN           4  \n",
       "4                   12.0      London Academy           5  \n",
       "...                  ...                 ...         ...  \n",
       "4698                24.0  Birmingham Academy        4594  \n",
       "4699                27.0  Birmingham Academy        4595  \n",
       "4700                24.0      London Academy        4596  \n",
       "4701                19.0  Birmingham Academy        4597  \n",
       "4702                24.0  Birmingham Academy        4598  \n",
       "\n",
       "[4691 rows x 20 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2cd0a3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = candidates.drop_duplicates(subset='person_id', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ce2b11e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SQLite connection\n",
    "conn = sqlite3.connect('my_database24.db')\n",
    "\n",
    "person_id = 24  # change this to the specific name_id you're interested in\n",
    "\n",
    "# SQLite query string\n",
    "query = '''\n",
    "SELECT *\n",
    "FROM candidates\n",
    "LEFT JOIN academy ON candidates.person_id = academy.person_id\n",
    "LEFT JOIN academy_results ON candidates.person_id = academy_results.person_id\n",
    "LEFT JOIN strength_junc ON candidates.person_id = strength_junc.person_id\n",
    "LEFT JOIN weakness_junc ON candidates.person_id = weakness_junc.person_id\n",
    "LEFT JOIN tech_scores ON candidates.person_id = tech_scores.person_id\n",
    "WHERE candidates.person_id = ?\n",
    "'''\n",
    "\n",
    "\n",
    "# Execute the query\n",
    "df_query = pd.read_sql_query(query, conn, params=(person_id,))\n",
    "\n",
    "\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d3079cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_id</th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "      <th>dob</th>\n",
       "      <th>email</th>\n",
       "      <th>phone_number</th>\n",
       "      <th>uni</th>\n",
       "      <th>degree</th>\n",
       "      <th>invited_by</th>\n",
       "      <th>invite_date</th>\n",
       "      <th>...</th>\n",
       "      <th>Professional</th>\n",
       "      <th>Studious</th>\n",
       "      <th>person_id</th>\n",
       "      <th>person_id</th>\n",
       "      <th>strength_id</th>\n",
       "      <th>person_id</th>\n",
       "      <th>weakness_id</th>\n",
       "      <th>person_id</th>\n",
       "      <th>technology</th>\n",
       "      <th>self_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>RIP MCILVENNY</td>\n",
       "      <td>M</td>\n",
       "      <td>1999-05-31 00:00:00</td>\n",
       "      <td>rmcilvennyn@tripod.com</td>\n",
       "      <td>443402647575</td>\n",
       "      <td>University of Hertfordshire</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GISMO TILLING</td>\n",
       "      <td>2019-04-18 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>24</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>15</td>\n",
       "      <td>24</td>\n",
       "      <td>R</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>RIP MCILVENNY</td>\n",
       "      <td>M</td>\n",
       "      <td>1999-05-31 00:00:00</td>\n",
       "      <td>rmcilvennyn@tripod.com</td>\n",
       "      <td>443402647575</td>\n",
       "      <td>University of Hertfordshire</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GISMO TILLING</td>\n",
       "      <td>2019-04-18 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>24</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>15</td>\n",
       "      <td>24</td>\n",
       "      <td>SPSS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>RIP MCILVENNY</td>\n",
       "      <td>M</td>\n",
       "      <td>1999-05-31 00:00:00</td>\n",
       "      <td>rmcilvennyn@tripod.com</td>\n",
       "      <td>443402647575</td>\n",
       "      <td>University of Hertfordshire</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GISMO TILLING</td>\n",
       "      <td>2019-04-18 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>24</td>\n",
       "      <td>17</td>\n",
       "      <td>24</td>\n",
       "      <td>15</td>\n",
       "      <td>24</td>\n",
       "      <td>R</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>RIP MCILVENNY</td>\n",
       "      <td>M</td>\n",
       "      <td>1999-05-31 00:00:00</td>\n",
       "      <td>rmcilvennyn@tripod.com</td>\n",
       "      <td>443402647575</td>\n",
       "      <td>University of Hertfordshire</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GISMO TILLING</td>\n",
       "      <td>2019-04-18 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>24</td>\n",
       "      <td>17</td>\n",
       "      <td>24</td>\n",
       "      <td>15</td>\n",
       "      <td>24</td>\n",
       "      <td>SPSS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   person_id           name gender                  dob  \\\n",
       "0         24  RIP MCILVENNY      M  1999-05-31 00:00:00   \n",
       "1         24  RIP MCILVENNY      M  1999-05-31 00:00:00   \n",
       "2         24  RIP MCILVENNY      M  1999-05-31 00:00:00   \n",
       "3         24  RIP MCILVENNY      M  1999-05-31 00:00:00   \n",
       "\n",
       "                    email  phone_number                          uni  degree  \\\n",
       "0  rmcilvennyn@tripod.com  443402647575  University of Hertfordshire     1.0   \n",
       "1  rmcilvennyn@tripod.com  443402647575  University of Hertfordshire     1.0   \n",
       "2  rmcilvennyn@tripod.com  443402647575  University of Hertfordshire     1.0   \n",
       "3  rmcilvennyn@tripod.com  443402647575  University of Hertfordshire     1.0   \n",
       "\n",
       "      invited_by          invite_date  ... Professional Studious  person_id  \\\n",
       "0  GISMO TILLING  2019-04-18 00:00:00  ...         None     None       None   \n",
       "1  GISMO TILLING  2019-04-18 00:00:00  ...         None     None       None   \n",
       "2  GISMO TILLING  2019-04-18 00:00:00  ...         None     None       None   \n",
       "3  GISMO TILLING  2019-04-18 00:00:00  ...         None     None       None   \n",
       "\n",
       "   person_id strength_id  person_id  weakness_id  person_id technology  \\\n",
       "0         24          13         24           15         24          R   \n",
       "1         24          13         24           15         24       SPSS   \n",
       "2         24          17         24           15         24          R   \n",
       "3         24          17         24           15         24       SPSS   \n",
       "\n",
       "   self_score  \n",
       "0           2  \n",
       "1           3  \n",
       "2           2  \n",
       "3           3  \n",
       "\n",
       "[4 rows x 38 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d108e760",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
