{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9a90d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from file_extraction import *\n",
    "from to_dataframe import *\n",
    "from clean_dfs import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d868ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_dict, academy_csvs_file_names = extract()\n",
    "dataframes = convert(files_dict, academy_csvs_file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d769ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_academy_csv = dataframes['academy_csv']\n",
    "df_academy_csv = clean_academy_csv(df_academy_csv)\n",
    "display(df_academy_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6b1602",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_csv = dataframes['csv']\n",
    "df_csv = clean_talent_csv(df_csv)\n",
    "display(df_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d46bc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json = dataframes['json']\n",
    "df_json = clean_talent_json(df_json)\n",
    "display(df_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dca2e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_txt = dataframes['txt']\n",
    "df_txt = clean_talent_txt(df_txt)\n",
    "display(df_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e09be3",
   "metadata": {},
   "source": [
    "# Generate Candidates Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f4a3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_person_ids(applicants):\n",
    "    applicants = applicants.reset_index().reset_index().drop(['index', 'id'], axis=1).rename(columns={'level_0':'person_id'})\n",
    "    return applicants\n",
    "\n",
    " \n",
    "\n",
    "def generate_candidates_df(applicants, talents, sparta_day_results):\n",
    "    applicants_and_talents = applicants.merge(talents, \n",
    "                                              left_on=['name', 'invite_date'], \n",
    "                                              right_on=['name', 'date'], \n",
    "                                              how='left')\n",
    "\n",
    "    candidates = applicants_and_talents.merge(sparta_day_results, \n",
    "                                              left_on=['name', 'invite_date'], \n",
    "                                              right_on=['name', 'date'], \n",
    "                                              how='left')\n",
    "\n",
    "    candidates = candidates.drop(candidates.index[candidates.person_id.duplicated().tolist()].tolist())\n",
    "    candidates.reset_index(drop=True, inplace=True)\n",
    "    candidates['person_id'] = candidates.index + 1\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644c8641",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = generate_candidates_df(get_person_ids(df_csv), df_json, df_txt)\n",
    "display(candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9d1d79",
   "metadata": {},
   "source": [
    "# Generate Courses Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7385c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_courses_table(dataframe):\n",
    "    courses_df  = dataframe\n",
    "    courses_df = pd.DataFrame().assign(course = courses_df['course'], date = courses_df['date'])\n",
    "    courses_df['course_id'] = courses_df.groupby(['course']).ngroup()\n",
    "    courses_df = courses_df[['course', 'course_id', 'date']].copy()\n",
    "    courses_df.set_index('course_id', inplace=True)\n",
    "    courses_df.groupby(['course','date'])\n",
    "    courses_df = courses_df.drop_duplicates()\n",
    "    courses_df = courses_df.reset_index()\n",
    "    courses_df.index = courses_df.index + 1\n",
    "    courses_df['course_id'] = courses_df.index\n",
    "    courses_df = courses_df.rename(columns={\"course\": \"course_name\"})\n",
    "    \n",
    "    return courses_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab205ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "courses_table = generate_courses_table(df_academy_csv)\n",
    "display(courses_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c098a1",
   "metadata": {},
   "source": [
    "# Generate Weakness Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad4be64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# makes a weakness table dataframe\n",
    "def generate_weakness_df(df):\n",
    "    weaknesses_list = list()\n",
    "    \n",
    "    # for each row in the dataframe add distinct weaknesses to a list\n",
    "    for index, row in df.iterrows():\n",
    "        for weakness in row[\"weaknesses\"]:\n",
    "            if weakness not in weaknesses_list:\n",
    "                weaknesses_list.append(weakness)\n",
    "                \n",
    "    # turn weakneseses list into a dataframe and add a column for the weakness id            \n",
    "    weakness_table = pd.DataFrame(weaknesses_list, columns=['weakness'])\n",
    "    weakness_table.index = weakness_table.index + 1\n",
    "    weakness_table['weakness_id'] = weakness_table.index\n",
    "    return weakness_table          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f46195",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "weakness_df = generate_weakness_df(df_json)\n",
    "display(weakness_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1f7987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes talent jsons, talent csv, weakness dataframe as arguments\n",
    "def generate_weakness_junc_df(candidates, weakness_df):\n",
    "    weakness_junc_list = list()\n",
    "    \n",
    "    # for each row in the merged dataframe add (id, weakness) to a new dataframe for each weakness in weaknesses list\n",
    "    for index, row in candidates.iterrows():\n",
    "        person_id = row['person_id']\n",
    "        weaknesses = row['weaknesses']\n",
    "        \n",
    "        if type(weaknesses) == list:\n",
    "            for weakness in weaknesses:\n",
    "                weakness_junc_list.append([person_id, weakness])\n",
    "    \n",
    "    weakness_junc = pd.DataFrame(weakness_junc_list, columns=['person_id', 'weakness'])\n",
    "    \n",
    "    weakness_junc = pd.merge(weakness_junc, weakness_df, on='weakness')[['person_id', 'weakness_id']] \n",
    "        \n",
    "    return weakness_junc      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ef6683",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weakness_junc_df = generate_weakness_junc_df(candidates, weakness_df)\n",
    "display(weakness_junc_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a326c8",
   "metadata": {},
   "source": [
    "# Generate Strengths Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a41675",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_strengths_df(df):\n",
    "    # Create a new DataFrame for strengths column only\n",
    "    column_names = ['name', 'strengths']\n",
    "    strengths = df[column_names]\n",
    "\n",
    "    # Initialize an empty list to store row data\n",
    "    strengths_list = []\n",
    "\n",
    "    # Iterate over all rows\n",
    "    for index, row in strengths.iterrows():\n",
    "        strengths_list_row = row['strengths']\n",
    "\n",
    "        # Iterate over each strength in the list\n",
    "        for strength in strengths_list_row:\n",
    "            if strength not in strengths_list:\n",
    "                # Append row data to the list\n",
    "                strengths_list.append(strength)\n",
    "\n",
    "    # Create a new DataFrame from the list\n",
    "    strengths_df = pd.DataFrame({'strength': strengths_list})\n",
    "    strengths_df.index = strengths_df.index + 1\n",
    "    strengths_df['strength_id'] = strengths_df.index\n",
    "    # Return the new DataFrame\n",
    "    return strengths_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e7e245",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "strengths_df = generate_strengths_df(df_json)\n",
    "display(strengths_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deef4866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes talent jsons, talent csv, weakness dataframe as arguments\n",
    "def generate_strengths_junc_df(candidates, strengths_df):\n",
    "    strengths_junc_list = list()\n",
    "    \n",
    "    for index, row in candidates.iterrows():\n",
    "        person_id = row['person_id']\n",
    "        strengths = row['strengths']\n",
    "        \n",
    "        if type(strengths) == list:\n",
    "            for strength in strengths:\n",
    "                strengths_junc_list.append([person_id, strength])\n",
    "    \n",
    "    strengths_junc = pd.DataFrame(strengths_junc_list, columns=['person_id', 'strength'])\n",
    "\n",
    "    strengths_junc = pd.merge(strengths_junc, strengths_df, on='strength')[['person_id', 'strength_id']] \n",
    "        \n",
    "    return strengths_junc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cd13ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "strengths_junc_df = generate_strengths_junc_df(candidates, strengths_df)\n",
    "display(strengths_junc_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094f16b5",
   "metadata": {},
   "source": [
    "# Generate Address Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d0e951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# makes an address table dataframe \n",
    "def generate_address_df(df):\n",
    "    addresses = list()\n",
    "    # for each row in the talent csv files, add each unique address, city and postcode to a list\n",
    "    for index, row in df.iterrows():\n",
    "                address_list = list()\n",
    "                address_list.append(row[\"address\"])\n",
    "                address_list.append(row[\"city\"])\n",
    "                address_list.append(row[\"postcode\"])\n",
    "                if address_list not in addresses:\n",
    "                    addresses.append(address_list)\n",
    "                    \n",
    "    address_table = pd.DataFrame(addresses, columns=[\"address\", \"city\", \"postcode\"])\n",
    "    address_table.index = address_table.index + 1\n",
    "    return address_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5156439",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(generate_address_df(df_csv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13501f3b",
   "metadata": {},
   "source": [
    "# Generate Tech Score Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfb56b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tss_df(df, candidates):\n",
    "    #Create names lists\n",
    "    names = []\n",
    "    technologies = []\n",
    "    self_scores = []\n",
    "\n",
    "    #Loop through dataframe\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            techs = list(row['tech_self_score'].keys())\n",
    "            for tech in techs:\n",
    "                names.append(row['name'].upper())\n",
    "                technologies.append(tech)\n",
    "                self_scores.append(row['tech_self_score'][tech])\n",
    "        except AttributeError:\n",
    "            continue\n",
    "\n",
    "    tech_self_scores = pd.DataFrame({'name':names, 'technology':technologies, 'self_score': self_scores})\n",
    "    merged = pd.merge(tech_self_scores, candidates, on='name')[['person_id', 'technology', 'self_score']] \n",
    "    \n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b33ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_scores = generate_tss_df(df_json, candidates)\n",
    "display(tech_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd1d46b",
   "metadata": {},
   "source": [
    "# Generate Candidates Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3434ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_person_ids(applicants):\n",
    "#     applicants = applicants.reset_index().reset_index().drop(['index', 'id'], axis=1).rename(columns={'level_0':'person_id'})\n",
    "#     return applicants\n",
    "\n",
    " \n",
    "\n",
    "# def generate_candidates_df(applicants, talents, sparta_day_results):\n",
    "#     applicants_and_talents = applicants.merge(talents, \n",
    "#                                               left_on=['name', 'invite_date'], \n",
    "#                                               right_on=['name', 'date'], \n",
    "#                                               how='left')\n",
    "\n",
    "#     candidates = applicants_and_talents.merge(sparta_day_results, \n",
    "#                                               left_on=['name', 'invite_date'], \n",
    "#                                               right_on=['name', 'date'], \n",
    "#                                               how='left')\n",
    "\n",
    "#     candidates = candidates.drop(candidates.index[candidates.person_id.duplicated().tolist()].tolist())\n",
    "#     candidates.reset_index(drop=True, inplace=True)\n",
    "#     candidates['person_id'] = candidates.index + 1\n",
    "#     return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57204982",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# candidates = generate_candidates_df(get_person_ids(df_csv), df_json, df_txt)\n",
    "# display(candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6910f5",
   "metadata": {},
   "source": [
    "# Generate Academy Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d634c0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_academy_table(df_academy_csv, courses_table, candidates):\n",
    "    merged = pd.merge(df_academy_csv, courses_table, left_on='course', right_on='course_name')[['name', 'course_id']]\n",
    "    academy_table = pd.merge(merged, candidates, on='name')[['person_id', 'course_id']] \n",
    "    return academy_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509ea9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "academy_table = generate_academy_table(df_academy_csv, courses_table, candidates)\n",
    "display(academy_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f274eb1",
   "metadata": {},
   "source": [
    "# Generate Trainers Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d63f7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_trainers_table(df):\n",
    "    old_name = \"Ely Kely\"\n",
    "    new_name = \"Elly Kelly\"\n",
    "    df.loc[:, [\"trainer\"]] = df.loc[:, [\"trainer\"]].replace(old_name, new_name)\n",
    "    trainers_course = df[[\"trainer\", \"course\", \"date\"]]\n",
    "    trainer_course = trainers_course.drop_duplicates(subset = [\"date\"], keep= \"first\")\n",
    "    trainer_course['trainer_id'] = range(1, len(trainer_course) + 1)\n",
    "    trainers = trainer_course.set_index('trainer_id')\n",
    "    trainers_table = trainers.drop(['course', 'date'], axis=1).drop_duplicates()\n",
    "    trainers = trainers.rename(columns={\"course\": \"course_name\"})\n",
    "    trainers['trainer_id'] = trainers.index\n",
    "    return trainers, trainers_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2133156c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainers, trainers_table = generate_trainers_table(df_academy_csv)\n",
    "display(trainers_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29909e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(trainers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17345118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_trainers_junc(df_trainers, df_courses):\n",
    "    trainers_junc = pd.merge(df_trainers, df_courses, on='course_name')[['course_id', 'trainer_id']] \n",
    "    return trainers_junc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83bc87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainers_junc = generate_trainers_junc(trainers, courses_table)\n",
    "display(trainers_junc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570f5b40",
   "metadata": {},
   "source": [
    "# Generate Courses Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f47705e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_courses_table(dataframe):\n",
    "#     courses_df  = dataframe\n",
    "#     courses_df = pd.DataFrame().assign(course = courses_df['course'], date = courses_df['date'])\n",
    "#     courses_df['course_id'] = courses_df.groupby(['course']).ngroup()\n",
    "#     courses_df = courses_df[['course', 'course_id', 'date']].copy()\n",
    "#     courses_df.set_index('course_id', inplace=True)\n",
    "#     courses_df.groupby(['course','date'])\n",
    "#     courses_df = courses_df.drop_duplicates()\n",
    "#     courses_df = courses_df.reset_index()\n",
    "#     courses_df.index = courses_df.index + 1\n",
    "#     courses_df['course_id'] = courses_df.index\n",
    "#     courses_df = courses_df.rename(columns={\"course\": \"course_name\"})\n",
    "    \n",
    "#     return courses_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad83053f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# courses_table = generate_courses_table(df_academy_csv)\n",
    "# display(courses_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d780dfd0",
   "metadata": {},
   "source": [
    "# Generate Academy Results Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0579619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def use(key: str):\n",
    "    s3 = boto3.client('s3')\n",
    "    obj = s3.get_object(Bucket='data-eng-228-final-project', Key=key)\n",
    "    filetype = key[key.index('.'):]\n",
    "    if filetype == '.csv':\n",
    "        data = pd.read_csv(obj['Body'])\n",
    "    elif filetype == '.json':\n",
    "        data = json.load(obj['Body'])\n",
    "    elif filetype == '.txt':\n",
    "        data = obj['Body'].read().decode('utf-8')\n",
    "    return data\n",
    "\n",
    "\n",
    "def make_wide(table):\n",
    "    academy_results_wide = table.pivot(index=['name', 'week_no'],\n",
    "                                       columns='attribute',\n",
    "                                       values='score')\n",
    "    academy_results = academy_results_wide.reset_index()\n",
    "    return academy_results\n",
    "\n",
    "\n",
    "def make_upper(df, attribute: str='name'):\n",
    "    return df[attribute].transform(lambda attr: attr.upper())\n",
    "\n",
    "\n",
    "def transform_acares(keystrings: list):\n",
    "    tables = []\n",
    "\n",
    "    for keystring in keystrings:\n",
    "        current_ar = use(keystring)\n",
    "        current_ar['name'] = make_upper(current_ar, 'name')\n",
    "        raw_attributes = current_ar.columns[2:]\n",
    "\n",
    "        names = []\n",
    "        week_numbers = []\n",
    "        attributes = []\n",
    "        scores = []\n",
    "\n",
    "        for name in current_ar['name']:\n",
    "            for attribute in raw_attributes:\n",
    "                names.append(name)\n",
    "                week_numbers.append(attribute[attribute.index('W') + 1:])\n",
    "                attributes.append(attribute[:attribute.index('_')])\n",
    "                scores.append(float(current_ar[current_ar['name'] == name][attribute].tolist()[0]))\n",
    "        academy_results_long = pd.DataFrame({'name': names,\n",
    "                                             'week_no': week_numbers,\n",
    "                                             'attribute': attributes,\n",
    "                                             'score': scores})\n",
    "        tables.append(academy_results_long)\n",
    "    return pd.concat(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aed0079",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client('s3')\n",
    "files_dict = {'academy_csv': [], 'json': [], 'txt': [], 'csv': []}\n",
    "academy_csvs_file_names = extract_file_type(s3_client, 'Academy', files_dict, 'csv')\n",
    "df1 = transform_acares(academy_csvs_file_names)\n",
    "academy_results = make_wide(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618b3610",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_person_id_to_acares(candidates, academy_results):\n",
    "    passed_candidates = candidates[(candidates.result == 'PASS').tolist()]\n",
    "    passed_candidates\n",
    "\n",
    " \n",
    "\n",
    "    academy_results = academy_results.merge(passed_candidates[['person_id', 'name']], left_on='name', right_on='name')\n",
    "    return academy_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be2c02b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "join_person_id_to_acares(candidates, academy_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
